---
title: "Test_case_study"
author: "Achyuth Sai Patha"
date: "2024-10-09"
output: pdf_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load Data
# data <- read.csv("C://Users/achyu/OneDrive/Documents/1 - Project/Case_Study/LPGA.csv")
data <- read.csv("C:/Users/sammc/OneDrive/Desktop/School/MAS/Fall 2024/Regression/Case Study 551/LPGA.csv")
```
## *Introduction*
- The aim of this study is to create a predictive model to dertermine the prize money a golfer will win per round ("przrnd") based on various performance variables from the Ladies Professional Golf Association. 

- This model will be constructed using data from 100 golfers featured in the Ladies Professional Golf Association. There are nine variables included in the data set, with "przrnd" being the variable of interest.


- "przrnd": This variable represents the amount of prize money won per round of the golfer's career (in American dollars and cents)

- With "przrnd" as our response variable, that leaves 8 other possible predictor variables:

- "Golfer": This variable holds a string with the name of each of the 100 golfers. This can be thought of as a categorical variable with each name as a different level.

- "rounds": This variable holds integers for the total number of rounds each golfer has played in their career.

- "avedist": This variable represents the average distance each golfer hits the ball with a driver in yards (typically used at the start of a hole or on long holes)

- "pctfrwy": Defined as the percent of fairways hit in the golfer's career, this variable generally indicates accuracy and control from the tee.

- "pctgrn": This variable tracks the percentage a golfer's ball reaches the putting surface in par minus two strokes or better.
This variable generally indicates overall play from tee to green.

- "aveputt": Average number of putts a golfer takes in an 18-hole round. Lower numbers often indicate that a golfer is more efficient at putting or chipping in the ball.

- "avesand": This variable counts the number of times, on average, a golfer hits from a sand pit. Lower numbers typically indicate the golfer is avoiding sand traps.

- "pctsandsv": This variable measures how often a golfer gets the ball into the hole in two shots or less after hitting from a sand pit. This is calculated by the following equation: (Number of successful sand saves) / (Number of sand bunker shots) x 100

- In order to balance over and under fitting, we must find the most impactful predictor variables to include in our model. This will be done by creating summary statistics and graphics, and model fitting.

## *Summary Statistics and Graphics*

- After thinking about the definition of each variable, none of them have practical negative values or zero points.

- The percentage variables will be left as is since they are already on an interpretable scale (0 - 100).

- Przrnd, rounds, avedist, aveputt, and avesand may need log transformations (if heavily skewed/have large outliers).

- Also, standardization of predictors would be necessary for comparing effect sizes.

- Normalization may make sense since it would constrain all the data between 0 and 1 (essentially the same scale as the percentage variables), however interpretation then becomes an issue.

- Scaling predictors by removing the mean and dividing by the standard deviation (using "scale()") will be beneficial for interpretation and comparing effect sizes

- Log transformations and scaling predictors will be used to restructure the data.

```{r}
library(car)
library(ggplot2)
library(gridExtra)
library(rstanarm)

sum(is.na(data)) # No NAs

str(data) # One character variable (Golfer)


# "Golfer" is a vector of characters, so we need to convert to factors to create plots
data$Golfer <- as.factor(data$Golfer)
# Initial glance at relationships between variables
scatterplotMatrix(data)


# Check skewness (see if log transformations would be useful)
variables <- c("rounds", "avedist", "aveputt", "avesand", "przrnd")

par(mfrow=c(2, 2))
for(var in variables) {
  hist(data[[var]], main=paste("Histogram of", var), xlab="Value")
}

```

- It appears that avesand and our przrnd are right skewed. Przrnd is heavily right skewed and should definitely be log transformed in the models as is it our response variable.

- Avesand is less right skewed, and may or may not be useful in the model. Model comparisons later will help identify if a log transform of avesand will produce a better model.

- Furthermore, there appears to be relationships between our response and predictors "rounds", "avedsit", "pctgrn", "aveputt" and maybe "avesand".

- The predictors "rounds", "avedsit", and "pctgrn" are all positive.

- In golf terms, golfers that have played more rounds, hit the ball further with a driver, or have a higher percent green tend to earn more money.

- Also, the negative relationship between the response and "aveputt" and "avesand" make sense in a golf perspective. Golfers that get the ball in the hole in fewer putts or hit less from in the sand tend to win more prize money.

- There also seems to be noticable interactions between rounds:avedist, rounds:pctgrn, rounds:aveputt, rounds:avgsand, avedist:pctgrn, and pctgrn:avesand. The predictors "rounds", "avedsit", "pctgrn", "aveputt" and "avesand" (along with their interactions) will be considered for fitting and evaluation in future models.


## *Analysis*

### **Data Preparation**
Load the data and inspect it to identify missing values, categorical variables, and numeric variables.

```{r}
sum(is.na(data)) # Check for missing values
str(data)        # Inspect structure of the data
```
- It is important to ensure that the data is clean and ready for analysis by removing missing values or handling them appropriately. We also convert "Golfer" to a factor as it is categorical.

### **Exploratory Data Analysis**

```{r}
plots <- list()

variables <- c("rounds", "avedist", "aveputt", "avesand", "przrnd")

# Create each histogram and store it in the list
for (var in variables) {
  p <- ggplot(data, aes_string(x = var)) + 
    geom_histogram(bins = 30, fill = "gray", color = "black") + 
    ggtitle(paste("Histogram of", var)) + 
    xlab(var) + 
    theme_minimal()
  
  plots[[var]] <- p  # Store each plot in the list
}

# Arrange and display the plots in a grid
grid.arrange(grobs = plots, ncol = 2)

```
- This step is important for identifying the need for transformations and understanding the variable distributions. Skewness was detected in prznd and avesand, motivating the decision to log-transform them.

### **Model Fitting**

```{r}
# Remove golfer from data set (explained in analysis)
data_no_golfer <- data
data_no_golfer$Golfer <- NULL
```

- The Golfer variable was removed from our models.

- First, it was causing divergent transitions in model fitting and errors in kfold comparisons.

- The decision to remove it from "all predictors" model makes sense since the "amount of prize money won per round" is likely not dependent on the name of the golfer.

- If this was the case, then the tournament is likely biased toward certain golfers and warrants further exploration.

- For the purposes of our analysis, we assume that the rounds of golf are fair and not biased toward any one golfer.

```{r}
# Scale predictors so they are all on the same scale (so they can be compared later)
predictors <- c("rounds", "avedist", "pctgrn", "aveputt", "avesand", "pctsndsv")
data_scaled <- data_no_golfer
data_scaled[,predictors] <- scale(data_no_golfer[,predictors])

variables <- c("rounds", "avedist", "aveputt", "avesand", "przrnd")

par(mfrow=c(2, 2))
for(var in variables) {
  hist(data_scaled[[var]], main=paste("Hist of scaled", var), xlab="Value")
}
```

- The remaining predictor variables were scaled using the scale() function.

- Histograms of the scaled predictors are shown for comparisons to each other and to the original scales.

- This allowed us to compare effect sizes later on.

```{r}
# GLM with all predictors except Golfer name (explained below)
fit_all <- stan_glm(data = data_scaled, przrnd ~ ., refresh = 0)

# GLM with 5 predictors mentioned in summary stats with no interactions or transformations
fit_1 <- stan_glm(data = data_scaled, przrnd ~ rounds + avedist + pctgrn + aveputt + avesand, refresh = 0)

# GLM with 5 predictors and log transformations of response
fit_2 <- stan_glm(data = data_scaled, log(przrnd) ~ rounds + avedist + pctgrn + aveputt + avesand, refresh = 0)

# GLM with 5 predictors and log transformations of response and avesand
# Need to log transform avesand first then scale
data_logavesand <- data_scaled

data_logavesand$avesand_unscaled <- data_scaled$avesand * sd(data_no_golfer$avesand) + mean(data_no_golfer$avesand)

data_logavesand$log_avesand <- log(data_logavesand$avesand_unscaled)

data_logavesand$scaled_log_avesand <- scale(data_logavesand$log_avesand)

fit_3 <- stan_glm(data = data_logavesand, log(przrnd) ~ rounds + avedist + pctgrn + aveputt + scaled_log_avesand, refresh = 0)


# Comparing first 4 models
kfold_all <- kfold(fit_all, k = 10)
kfold1 <- kfold(fit_1, k = 10)
kfold2 <- kfold(fit_2, k = 10)
kfold3 <- kfold(fit_3, k = 10)


# Subtract log(prszrnd) from fit 2 for comparison
kfold2_adj <- kfold2
kfold2_adj$pointwise[,1] <- kfold2$pointwise[,1] - log(data_scaled$przrnd)

kfold3_adj <- kfold3
kfold3_adj$pointwise[,1] <- kfold3$pointwise[,1] - log(data_scaled$przrnd)


loo_compare(kfold_all,kfold1,kfold2_adj,kfold3_adj)

# Testing R^2 for fit 2 and 3
round(median(bayes_R2(fit_2)), 2)
round(median(loo_R2(fit_2)), 2)

round(median(bayes_R2(fit_3)), 2)
round(median(loo_R2(fit_3)), 2)
```

- Models were fit using several different combinations of predictors.

- "Fit_all" modeled all the predictors except golfers.

- Next, we modeled the data with the predictors decided upon at the end of the "Summary Stats and Graphics" section.

- The next two models looked at log transformations.

- Fit 2 looked at log transforming the response, and fit 3 looked at log transforming both the response and predictor "avesand".

- The scaled data presented problems when trying to cross validate fit 3 (which has a log transformed "avesand" predictor).

- After the scaling process, some of the values of "avesand" got scaled to be negative and the log of a negative number is undefined. So the variable had to get "unscaled", then transformed, and then rescaled.

- Again, fit 2 and fit 3 examined the effect of log transformations.

- Fit 3 seemed to fit better, but only slightly.

- Log transforming avesand seemed to have a minimal effect on the fit on the model.

- Additionally, both fit 2 and fit 3 have similar out of sample and in sample variance (R\^2).

- To aid in interpretation, fit 2 will move on and be used for comparing subsequent models.

```{r}
# Trying a selection prior
p <- ncol(data_scaled) - 1
n <- nrow(data_scaled)
p0 <- 3
slab_scale <- sqrt(0.3/p0)*sd(data_scaled$przrnd)
global_scale <- (p0/(p - p0))/sqrt(n)
fit_hs <- stan_glm(data = data_scaled, log(przrnd) ~ ., refresh = 0,
  prior=hs(global_scale=global_scale,
  slab_scale=slab_scale))

# Horseshoe prior had "divergent transitions", so trying normal prior
fit_normal <- stan_glm(data = data_scaled, log(przrnd) ~ .,  
                       prior = normal(location = 0, scale = 0.25),
                       refresh = 0)

kfold_normal <- kfold(fit_normal, k = 10)

loo_compare(kfold2,kfold_normal)

```

- Next, a few prior distributions were tested for model fit.

- A horseshoe prior produced "divergent transitions", which makes the model less believable / trustworthy.

- This model was discarded.

- A normal prior was then tested and compared to fit 2.

- The normal prior assumes that the coefficients of the predictors follow a normal distribution. However, we do not have enough domain, or statistical, knowledge to confidently assume this.

- Also, fit 2 seemed to model the data slightly better, but a normal prior is more resistant to overfitting since it biases the coefficients toward 0. Only if the data supports large values will it be "pulled" less toward zero.

- Furthermore, a model based on a prior would be powerful at prediction since the model can be used to make direct probability statements about parameters.

- Unfortunately, we can't confidently assume a normal prior in this case, so fit 2 will move on again.

```{r}
# Try model with interaction between rounds and avgdist
fit_5 <- stan_glm(data = data_scaled, log(przrnd) ~ rounds + avedist + pctgrn + aveputt + avesand + rounds:avedist, refresh = 0)

kfold5 <- kfold(fit_5, k = 10)

loo_compare(kfold2,kfold5)

```

- Finally, a model using the interaction between rounds and avedist was fit.

- These two variables were chosen since they seemed to have the most probable relationship between themselves, and with the response.

- This model did not fit the data noticeably better than fit 2.

- Furthermore, interactions greatly decrease interpretation, so this model was disregarded.

- Maybe there is a more elegant way to deal with interactions in this data, but it is not clear to us at this time.

```{r}
# Inspect and plot fit_2
fit_2

coef(fit_2)

round(median(bayes_R2(fit_2)), 2)
round(median(loo_R2(fit_2)), 2)

plot(fitted(fit_2), resid(fit_2),
 xlab = "Predicted values from fit 2",
 ylab = "Residuals",
 main = "Residual plot")
abline(h=0, col="red")
```

- After comparing different models, it appears that fitting the data by log transforming our response (przrnd), and including predictors "rounds", "avedist", "pctgrn", "aveputt" and "avesand" results in the best fitting model.

- A residuals plot for this model shows no obvious patterns or relationships between the predicted values and the residuals.

- Also, there is random scattering around the center line with no obvious outliers, and most residuals are between -1 and 1.

- Based on residuals plot and model comparisons, this linear model appears to fit the data well and meet all assumptions.

```{r}
model <- fit_2
summary(model)
```

#### **Residuals**
- The difference between the observed and predicted values indicate that the model is fit. Here the residulas range from approximately -1.49 to 1.18 suggesting that more predictions are overstimating while others are underestimating the log of prize money.

*Summary Statistics*
- *Min:* -1.48871
- *1st Quartile (1Q):* -0.28464
- *Median:* 0.03672
- *3rd Quartile (3Q):* 0.29359
- *Max:* 1.18008

These shows that the residuals are relatively symmetrically distributed around the zero, which is a good sign for linear regression.

## *Coefficients*
- The coefficients represents the expected change in the log of prize money for a one-unit increase in each predictor while holding other variables constant.

- **Intercept**
Estimate: 2.8082295
    - This number reflects the expected log of prize money when all the predictor variables are zero. While it isn't usally practical to intercept this in real-world terms, it does provides a foundational reference point for the model.
    
P-value: 0.0644
    - This value is marginally significant, implying that the intercept might be close to zeor.
        
## *Rounds*
Estimate: 0.0275204
    - This suggests that for every additional round played, the log of prize money is likely to increase by about 0.0275, indicating a positive correlation.
    
P-value: 2.11e-13
    - This value is highly significant which means that the number of rounds played is a strong predictor of prize money.
    
## *Average Distance (avedist)*

Estimate: 0.0008562
    - For each additional unit of average distance, the log of prize money increases by roughly 0.0008562. However, this impact is quite small.
    
P-value: 0.8868
    - This is not significant, which indicates that average distance does not play a meaningful role in determining prize money in this model.
    
## *Percentage of Greens in Regulation (pctgrn)*
Estimate: 0.0933444
- Each percentage increase in greens in regulation correlates with an increase of about 0.0933 in the log of prize money, suggesting a positive relationship.

P-value: 8.16e-07
- This is also highly significant (***), reinforcing the importance of greens in regulation as a predictor.

## *Average Putts (aveputt)*
Estimate: -0.1133594
- For every additional putt per round, the log of prize money is expected to decrease by approximately 0.1134, indicating a negative relationship.

P-value: 2.52e-06
- This is significant (***), showing that having more putts per round adversely affects earnings.

## *Log of Average Sand Shots (log_avesand)*
Estimate: 0.0455508
- For each unit increase in the log of average sand shots, the log of prize money is expected to increase by about 0.0456. However, this coefficient might not hold practical significance.

P-value: 0.8240
- This is not significant, indicating that average sand shots do not have a substantial impact on prize money.

---
Overall, the results suggests that the number of rounds played and percentage of greens in regulation significatnly influence prize money, while the average number of putts negatively affets it. Average distance and average sand shots do not appear to have meaningful contributions to predict prize money in this context.

### **Model Assumptions & Diagnostics**
```{r}
par(mfrow = c(2,2))
plot(model)
```


Explain about plots

### **Multicollinearity Chedk**

```{r}
vif(model)
```


Explain about tht variance inflation factor 


## *Interpretatins of Results*






